{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1SKH1vJJVc98"
   },
   "source": [
    "# Transfer Learning to classify keep or throwaway necklace model with VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After deciding to use the VGG16 model, my goal was to then decide what kind of labels I on the images I would use. Did I need to categorize the necklaces by type, as Etsy had done? Or could I simply just separate necklace images from non-necklace images?   \n",
    "  \n",
    "This model tests the latter: I train the model to identify whether there was a necklace in the image that would like a picture someone would upload, or not.   \n",
    "  \n",
    "Once I do this, I then use the model to produce feature vectors over which I calculate the similarity. At this point, I can compare the results to that produced by a model trained on categorical labels.  \n",
    "  \n",
    "*This code was written for use on Google Colab.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ziREXkGQVuY3"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "PYrRaKZgVc-B",
    "outputId": "3a4c3a59-6fba-498d-a23c-9bed3d256832"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import metrics, optimizers\n",
    "%tensorflow_version 1.x\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kh8jDsFEVc-I"
   },
   "source": [
    "## Define paths & constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8efhkJ-lXzlh",
    "outputId": "2f4d4fe4-8a8f-4054-dd26-4175be69b3c8"
   },
   "outputs": [],
   "source": [
    "data_base_path = \"/content/drive/My Drive/data/labeled/\"\n",
    "save_dir = os.path.abspath(\"/content/drive/My Drive/Colab Notebooks/\")\n",
    "print(os.listdir(data_base_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "D7-LEgCkEeYI",
    "outputId": "25c8edf6-a359-4b38-b167-52fc4d25a088"
   },
   "outputs": [],
   "source": [
    "# Ensure data directory paths are correct\n",
    "print(len(os.listdir(data_base_path+\"throwaway/\")))\n",
    "print(len(os.listdir(data_base_path+\"keep/\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M0KYpfUlVc-G"
   },
   "outputs": [],
   "source": [
    "# Decide on constants for the model\n",
    "nb_classes = 2\n",
    "batch_size = 32\n",
    "nb_train_samples = batch_size*3\n",
    "nb_validation_samples = batch_size*1\n",
    "nb_epochs = 100\n",
    "\n",
    "img_height = 150\n",
    "img_width = 150\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Iw6HWdGeXiG"
   },
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zdvpCdRnV_rS"
   },
   "outputs": [],
   "source": [
    "# Extract base of VGG16 model:\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hK3mYviibW0h",
    "outputId": "b1d5679c-d2ff-44d2-ec58-2a8d18a0c1ac"
   },
   "outputs": [],
   "source": [
    "# Add 3 trainable layers on top:\n",
    "# (Tried adding different combination of additional layers &\n",
    "# dropout layers... this configuration yielded the best metrics)\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512*4, activation='relu'))\n",
    "model.add(Dense(512*4, activation='relu'))\n",
    "model.add(Dense(512*4, activation='relu'))\n",
    "\n",
    "# predict category\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "conv_base.trainable = True\n",
    "print('This is the number of trainable weights '\n",
    "      'before freezing the conv base:', len(model.trainable_weights))\n",
    "conv_base.trainable = False\n",
    "print('This is the number of trainable weights '\n",
    "      'after freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9w0OpCX1eOTz"
   },
   "source": [
    "## Image augmentation\n",
    "  \n",
    "Randomly generate training & validation data by performing horizontal flips, rotating, and stretching photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nECYgdddVc-Q"
   },
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    horizontal_flip=True, \n",
    "    rotation_range=40, \n",
    "    width_shift_range=.15,\n",
    "    height_shift_range=.15,\n",
    "    validation_split=0.2) # set 80/20 train/test data split\n",
    "\n",
    "#test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce train & validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "wtSHBBa5Vc-W",
    "outputId": "a4084642-4a6e-4579-9d92-2fcfd34ed714"
   },
   "outputs": [],
   "source": [
    "train_generator = train_gen.flow_from_directory(\n",
    "    data_base_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training') # set as training data\n",
    "    # shuffles by default\n",
    "\n",
    "validation_generator = train_gen.flow_from_directory(\n",
    "    data_base_path, # same directory as training data\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-OUXDWowVc-a"
   },
   "source": [
    "### Inspect a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Lh-GRNaVc-a"
   },
   "outputs": [],
   "source": [
    "sample_training_images, _ = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4i0_q0nGVc-e"
   },
   "outputs": [],
   "source": [
    "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GeU23H9HVc-g"
   },
   "outputs": [],
   "source": [
    "plotImages(sample_training_images[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ngxp9CM0Vc-v"
   },
   "source": [
    "## Compile transfer learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "i62SfFlEVc-s",
    "outputId": "7ac8ae9a-3d63-463f-dd7c-9c624245527d"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JfnASZr8kBUo"
   },
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ngxp9CM0Vc-v"
   },
   "source": [
    "## Compile transfer learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "Tried a variety of learning rates, number of epochs, and both SGD & Adam optimizers. Please see ./tuning_binary_model/model_tuning.xlsx for a summary of changes in model accuracy with tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yw7mnr7kVc-w"
   },
   "outputs": [],
   "source": [
    "# Tried a variety of \n",
    "#LR1 = 0.001 # default with adam\n",
    "#LR2 = 0.01\n",
    "adam = optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "#sgd = optimizers.SGD(learning_rate=LR1, momentum=0.0, nesterov=False)\n",
    "#model.compile(optimizer = sgd, \n",
    "model.compile(optimizer = adam, \n",
    "              loss = 'sparse_categorical_crossentropy',  # for labeled data\n",
    "              metrics=['acc',f1_m,precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e-Auu1H7Vc-z"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1K8g1iquVc-z",
    "outputId": "65ddfd35-75a3-40ec-80f1-fa425ab3d95d"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "fit_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=nb_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "end_time = time.time()\n",
    "print(\"Total Time: \"+str(end_time - start_time)+\" seconds.\");''\n",
    "os.system('say \"your program has finished\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xnK0Ubh1ySxo",
    "outputId": "d8e8b593-08b1-4db9-f11f-0486b583da7c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0ac3345e9b97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ensure path where model is saved is correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#save_dir = os.path.join(os.getcwd(),'/drive/My Drive/Colab Notebooks/models/')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'save_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# ensure path where model is saved is correct\n",
    "#save_dir = os.path.join(os.getcwd(),'/drive/My Drive/Colab Notebooks/models/')\n",
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sQ9TdGbQVc-2"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "model.save('/content/drive/My Drive/data/VGG_binaryclassifier_v1_updated_4layers_LR0.0001_13000_imgtraining.h5')\n",
    "fit_history.history['time_total'] = end_time - start_time\n",
    "pickle.dump(fit_history.history,open('/content/drive/My Drive/data/VGG_binaryclassifier_v1_updated_4layers_LR0.0001_13000_imgtraining.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FobLrFy6eGcw"
   },
   "source": [
    "## Visualize model metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also visual model metrics in  \n",
    "./tuning_binary_model/compare_categorical_binary_stats.ipynb & \n",
    "./tuning_binary_model/recover_stats_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "colab_type": "code",
    "id": "DGh6yRAoVc-7",
    "outputId": "109dd6f2-f49e-4bec-91f1-b9d1a974d02f"
   },
   "outputs": [],
   "source": [
    "#print(fit_history.history.keys())\n",
    "acc = fit_history.history['acc']\n",
    "val_acc = fit_history.history['val_acc']\n",
    "\n",
    "loss = fit_history.history['loss']\n",
    "val_loss = fit_history.history['val_loss']\n",
    "\n",
    "epochs_range = range(nb_epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "#plt.savefig('./VGG.binary.v7.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "colab_type": "code",
    "id": "c1Vn_v5bqGWp",
    "outputId": "bd46ef6f-fbfb-4042-f8ec-5e0c17ad2a33"
   },
   "outputs": [],
   "source": [
    "#'f1_m', 'precision_m', 'recall_m', 'val_loss', 'val_acc', 'val_f1_m', 'val_precision_m', 'val_recall_m'\n",
    "#print(fit_history.history.keys())\n",
    "acc = fit_history.history['precision_m']\n",
    "val_acc = fit_history.history['val_precision_m']\n",
    "\n",
    "loss = fit_history.history['recall_m']\n",
    "val_loss = fit_history.history['val_recall_m']\n",
    "\n",
    "epochs_range = range(nb_epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Precision')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Precision')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Precision')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Recall')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Recall')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Recall')\n",
    "#plt.savefig('./VGG.binary.v7.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-OUXDWowVc-a"
   ],
   "name": "binary_VGG.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "insight",
   "language": "python",
   "name": "insight"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
